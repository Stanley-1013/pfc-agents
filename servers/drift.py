"""
Skill-Code Drift Detection Server
==================================

åµæ¸¬å°ˆæ¡ˆ Skillï¼ˆæ„åœ–å±¤ï¼‰èˆ‡ Code Graphï¼ˆç¾å¯¦å±¤ï¼‰ä¹‹é–“çš„åå·®ã€‚

æ–°æ¶æ§‹ï¼šè®€å–å°ˆæ¡ˆ .claude/skills/<project>/SKILL.md

åå·®é¡å‹ï¼š
1. missing_implementation - Skill å®šç¾©äº†ä½† Code æ²’å¯¦ä½œ
2. missing_spec - Code å­˜åœ¨ä½† Skill æ²’æ–‡æª”åŒ–
3. mismatch - å…©è€…éƒ½æœ‰ä½†å…§å®¹ä¸ä¸€è‡´
4. stale_spec - Skill æ–‡æª”éæ™‚

è¨­è¨ˆåŸå‰‡ï¼š
- åµæ¸¬åå·®ï¼Œä½†ä¸è‡ªå‹•ä¿®æ­£
- åå·®éœ€è¦äººé¡æ±ºç­–
- æä¾›å¯è¡Œå‹•çš„å»ºè­°
"""

import os
import re
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta

# =============================================================================
# SCHEMAï¼ˆä¾› Agent åƒè€ƒï¼‰
# =============================================================================

SCHEMA = """
=== Drift Detection API ===

get_drift_context(project, project_dir) -> Dict
    å–å¾— Drift åµæ¸¬æ‰€éœ€çš„ context è³‡æ–™ï¼ˆä¾› Drift Agent ä½¿ç”¨ï¼‰
    Args:
        project: å°ˆæ¡ˆåç¨±ï¼ˆç”¨æ–¼ Code Graph æŸ¥è©¢ï¼‰
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆ Skillï¼‰
    Returns: {
        'skill_content': str,       # SKILL.md å®Œæ•´å…§å®¹
        'skill_links': {            # parse_skill_links() çµæœ
            'links': [...],         # æ‰€æœ‰é€£çµ
            'sections': {...}       # æŒ‰ heading åˆ†çµ„
        },
        'code_nodes': [...],        # Code Graph ç¯€é»
        'code_files': [...],        # æª”æ¡ˆç¯€é»
        'code_stats': {...},        # Code Graph çµ±è¨ˆ
        'error': str | None
    }

detect_all_drifts(project, project_dir) -> DriftReport
    åŸºæœ¬å­˜åœ¨æ€§æª¢æŸ¥ï¼ˆæª”æ¡ˆé€£çµæ˜¯å¦æœ‰æ•ˆï¼‰
    æ·±å…¥èªç¾©åˆ†ææ‡‰ç”± Drift Agent åŸ·è¡Œ
    Returns: {
        'has_drift': bool,
        'drift_count': int,
        'drifts': [DriftItem],
        'summary': str,
        'checked_at': datetime
    }

detect_coverage_gaps(project) -> List[CoverageGap]
    åµæ¸¬æ¸¬è©¦è¦†è“‹ç¼ºå£
    Returns: [{
        'node_id': str,
        'node_kind': str,
        'name': str,
        'file_path': str,
        'has_test': bool
    }]

get_drift_summary(project, project_dir) -> str
    å–å¾—åå·®æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰
"""

# =============================================================================
# Data Models
# =============================================================================

@dataclass
class DriftItem:
    """å–®ä¸€åå·®é …ç›®"""
    id: str                              # å”¯ä¸€è­˜åˆ¥ç¬¦
    type: str                            # missing_implementation, missing_spec, mismatch, stale_spec
    severity: str                        # critical, high, medium, low
    ssot_item: Optional[str] = None      # SSOT å´çš„é …ç›®
    code_item: Optional[str] = None      # Code å´çš„é …ç›®
    description: str = ""
    suggestion: str = ""                 # å»ºè­°çš„ä¿®å¾©æ–¹å¼
    detected_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            'id': self.id,
            'type': self.type,
            'severity': self.severity,
            'ssot_item': self.ssot_item,
            'code_item': self.code_item,
            'description': self.description,
            'suggestion': self.suggestion,
            'detected_at': self.detected_at.isoformat() if self.detected_at else None
        }


@dataclass
class DriftReport:
    """åå·®å ±å‘Š"""
    has_drift: bool = False
    drift_count: int = 0
    drifts: List[DriftItem] = field(default_factory=list)
    summary: str = ""
    checked_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            'has_drift': self.has_drift,
            'drift_count': self.drift_count,
            'drifts': [d.to_dict() for d in self.drifts],
            'summary': self.summary,
            'checked_at': self.checked_at.isoformat()
        }


# =============================================================================
# Detection Logic
# =============================================================================

def get_drift_context(project: str, project_dir: str) -> Dict:
    """
    å–å¾— Drift åµæ¸¬æ‰€éœ€çš„ context è³‡æ–™

    ä¾› Drift Agent ä½¿ç”¨ï¼Œä¸åšåˆ¤æ–·ï¼Œåªæä¾›è³‡æ–™ã€‚
    Agent è² è²¬åˆ¤æ–·å“ªäº›æ˜¯çœŸæ­£çš„ driftã€‚

    Args:
        project: å°ˆæ¡ˆåç¨±ï¼ˆç”¨æ–¼ Code Graph æŸ¥è©¢ï¼‰
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆ Skillï¼‰

    Returns:
        {
            'skill_content': str,           # SKILL.md å®Œæ•´å…§å®¹
            'skill_links': {...},           # parse_skill_links() çµæœ
            'code_nodes': [...],            # Code Graph ç¯€é»
            'code_files': [...],            # æª”æ¡ˆç¯€é»
            'code_stats': {...},            # Code Graph çµ±è¨ˆ
            'error': str | None             # éŒ¯èª¤è¨Šæ¯
        }
    """
    from servers.ssot import parse_skill_links, load_skill, find_skill_dir
    from servers.code_graph import get_code_nodes, get_code_graph_stats

    result = {
        'skill_content': '',
        'skill_links': {'links': [], 'sections': {}},
        'code_nodes': [],
        'code_files': [],
        'code_stats': {'node_count': 0, 'edge_count': 0},
        'error': None
    }

    # 1. ç¢ºèªå°ˆæ¡ˆ Skill å­˜åœ¨
    skill_dir = find_skill_dir(project_dir)
    if not skill_dir:
        result['error'] = f"No Skill found in {project_dir}/.claude/skills/"
        return result

    # 2. å–å¾— Skill å®šç¾©
    try:
        skill_content = load_skill(project_dir)
        if not skill_content:
            result['error'] = "SKILL.md is empty"
            return result

        result['skill_content'] = skill_content
        result['skill_links'] = parse_skill_links(skill_content)
    except Exception as e:
        result['error'] = f"Failed to parse Skill: {str(e)}"
        return result

    # 3. å–å¾— Code Graph
    try:
        code_nodes = get_code_nodes(project, limit=1000)
        code_stats = get_code_graph_stats(project)

        result['code_nodes'] = code_nodes
        result['code_stats'] = code_stats
        result['code_files'] = [n for n in code_nodes if n['kind'] == 'file']

        if code_stats['node_count'] == 0:
            result['error'] = "Code Graph is empty. Run sync first."
    except Exception as e:
        result['error'] = f"Failed to get Code Graph: {str(e)}"

    return result


def detect_all_drifts(project: str, project_dir: str) -> DriftReport:
    """
    åµæ¸¬å°ˆæ¡ˆæ‰€æœ‰ Skill-Code åå·®ï¼ˆç°¡åŒ–ç‰ˆï¼‰

    æ­¤å‡½æ•¸æä¾›åŸºæœ¬çš„å­˜åœ¨æ€§æª¢æŸ¥ã€‚
    æ›´æ·±å…¥çš„èªç¾©åˆ†ææ‡‰ç”± Drift Agent åŸ·è¡Œã€‚

    Args:
        project: å°ˆæ¡ˆåç¨±ï¼ˆç”¨æ–¼ Code Graph æŸ¥è©¢ï¼‰
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆ Skillï¼‰
    """
    context = get_drift_context(project, project_dir)

    if context['error']:
        return DriftReport(
            has_drift=False,
            summary=f"Cannot detect drift: {context['error']}"
        )

    drifts = []
    drift_id = 0

    def make_drift_id():
        nonlocal drift_id
        drift_id += 1
        return f"drift-{project}-{drift_id:04d}"

    # åŸºæœ¬æª¢æŸ¥ï¼šé€£çµæŒ‡å‘çš„æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    from servers.ssot import find_skill_dir
    skill_dir = find_skill_dir(project_dir)

    for link in context['skill_links'].get('links', []):
        path = link.get('path', '')
        if not path:
            continue

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼ˆç›¸å°æ–¼ skill_dirï¼‰
        full_path = os.path.join(skill_dir, path)
        if not os.path.exists(full_path):
            # ä¹Ÿå˜—è©¦ç›¸å°æ–¼ project_dir
            alt_path = os.path.join(project_dir, path)
            if not os.path.exists(alt_path):
                drifts.append(DriftItem(
                    id=make_drift_id(),
                    type='missing_file',
                    severity='medium',
                    ssot_item=path,
                    description=f"Link '{link['name']}' points to non-existent file: {path}",
                    suggestion=f"Create the file or update the link in SKILL.md"
                ))

    # å»ºç«‹å ±å‘Š
    if drifts:
        summary = f"Found {len(drifts)} broken link(s). Run Drift Agent for deeper analysis."
    else:
        summary = "No broken links. Run Drift Agent for semantic drift detection."

    return DriftReport(
        has_drift=len(drifts) > 0,
        drift_count=len(drifts),
        drifts=drifts,
        summary=summary
    )


def detect_flow_drift(project: str, flow_name: str, project_dir: str) -> DriftReport:
    """åµæ¸¬ç‰¹å®š Flow çš„åå·®"""
    from servers.ssot import load_flow_spec
    from servers.code_graph import get_code_nodes

    drifts = []
    drift_id = 0

    def make_drift_id():
        nonlocal drift_id
        drift_id += 1
        return f"drift-{project}-{flow_name}-{drift_id:04d}"

    # 1. å–å¾— Flow Spec
    flow_spec = None
    try:
        flow_spec = load_flow_spec(flow_name, project_dir)
    except:
        pass

    if not flow_spec:
        return DriftReport(
            has_drift=True,
            drift_count=1,
            drifts=[DriftItem(
                id=make_drift_id(),
                type='missing_spec',
                severity='high',
                ssot_item=flow_name,
                description=f"Flow spec for '{flow_name}' not found",
                suggestion=f"Create .claude/skills/<project>/flows/{flow_name}.md"
            )],
            summary=f"Flow '{flow_name}' has no Skill specification"
        )

    # 2. å–å¾—ç›¸é—œ Code
    flow_name_lower = flow_name.lower()
    code_nodes = get_code_nodes(project, limit=500)

    related_code = []
    for node in code_nodes:
        if flow_name_lower in node.get('file_path', '').lower():
            related_code.append(node)
        elif flow_name_lower in node.get('name', '').lower():
            related_code.append(node)

    # 3. æª¢æŸ¥ä¸€è‡´æ€§
    # å¾ Spec ä¸­æå–é æœŸçš„ API endpoints
    api_pattern = re.compile(r'(?:GET|POST|PUT|DELETE|PATCH)\s+(/[^\s]+)', re.IGNORECASE)
    expected_apis = set(api_pattern.findall(flow_spec))

    # æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„ Code
    if not related_code and expected_apis:
        drifts.append(DriftItem(
            id=make_drift_id(),
            type='missing_implementation',
            severity='high',
            ssot_item=flow_name,
            description=f"Flow '{flow_name}' specifies APIs but no related code found",
            suggestion="Implement the APIs defined in the flow spec"
        ))

    # 4. æª¢æŸ¥æ¸¬è©¦è¦†è“‹
    has_test = any('test' in n.get('file_path', '').lower() for n in related_code)

    if not has_test:
        drifts.append(DriftItem(
            id=make_drift_id(),
            type='missing_implementation',
            severity='medium',
            ssot_item=flow_name,
            description=f"Flow '{flow_name}' has no test coverage",
            suggestion=f"Create test file for {flow_name}"
        ))

    # 6. å»ºç«‹å ±å‘Š
    if drifts:
        summary = f"Flow '{flow_name}' has {len(drifts)} drift(s)"
    else:
        summary = f"Flow '{flow_name}' is in sync with code"

    return DriftReport(
        has_drift=len(drifts) > 0,
        drift_count=len(drifts),
        drifts=drifts,
        summary=summary
    )


def detect_coverage_gaps(project: str) -> List[Dict]:
    """
    åµæ¸¬æ¸¬è©¦è¦†è“‹ç¼ºå£

    æ‰¾å‡ºæ²’æœ‰å°æ‡‰æ¸¬è©¦çš„é‡è¦ç¨‹å¼ç¢¼ã€‚
    """
    from servers.code_graph import get_code_nodes, get_code_edges

    # å–å¾—æ‰€æœ‰ nodes
    nodes = get_code_nodes(project, limit=1000)
    edges = get_code_edges(project, kind='tests', limit=500)

    # æ‰¾å‡ºè¢«æ¸¬è©¦è¦†è“‹çš„ nodes
    covered_ids = set(e['to_id'] for e in edges)

    # æ‰¾å‡ºé‡è¦ä½†æœªè¦†è“‹çš„ nodes
    gaps = []
    important_kinds = {'function', 'class', 'api'}

    for node in nodes:
        if node['kind'] not in important_kinds:
            continue

        # è·³éæ¸¬è©¦æª”æ¡ˆæœ¬èº«
        if 'test' in node.get('file_path', '').lower():
            continue

        # è·³é private å‡½å¼
        if node.get('visibility') == 'private':
            continue

        # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦
        has_test = node['id'] in covered_ids

        # ä¹Ÿç”¨æª”æ¡ˆåç¨±å•Ÿç™¼å¼æª¢æŸ¥
        if not has_test:
            file_path = node.get('file_path', '')
            file_stem = os.path.splitext(os.path.basename(file_path))[0]
            test_patterns = [
                f"{file_stem}.test",
                f"{file_stem}.spec",
                f"test_{file_stem}",
            ]
            for test_node in nodes:
                if test_node['kind'] == 'file' and 'test' in test_node.get('file_path', '').lower():
                    test_file = os.path.basename(test_node.get('file_path', '')).lower()
                    if any(p.lower() in test_file for p in test_patterns):
                        has_test = True
                        break

        if not has_test:
            gaps.append({
                'node_id': node['id'],
                'node_kind': node['kind'],
                'name': node['name'],
                'file_path': node.get('file_path'),
                'line_start': node.get('line_start'),
                'has_test': False
            })

    return gaps


# =============================================================================
# Reporting
# =============================================================================

def get_drift_summary(project: str, project_dir: str = None) -> str:
    """å–å¾—åå·®æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰

    Args:
        project: å°ˆæ¡ˆåç¨±
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆç´š SSOTï¼‰
    """
    report = detect_all_drifts(project, project_dir)

    lines = [
        "# SSOT-Code Drift Report",
        "",
        f"**Project**: {project}",
        f"**Checked at**: {report.checked_at.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Status**: {'âš ï¸ Drift detected' if report.has_drift else 'âœ… In sync'}",
        "",
    ]

    if not report.has_drift:
        lines.append("No drift detected. SSOT and Code are in sync.")
        return "\n".join(lines)

    lines.append(f"## Summary")
    lines.append("")
    lines.append(report.summary)
    lines.append("")

    # æŒ‰åš´é‡ç¨‹åº¦åˆ†çµ„
    by_severity = {'critical': [], 'high': [], 'medium': [], 'low': []}
    for drift in report.drifts:
        by_severity.get(drift.severity, by_severity['medium']).append(drift)

    severity_icons = {
        'critical': 'ğŸ”´',
        'high': 'ğŸŸ ',
        'medium': 'ğŸŸ¡',
        'low': 'ğŸŸ¢'
    }

    for severity in ['critical', 'high', 'medium', 'low']:
        items = by_severity[severity]
        if not items:
            continue

        lines.append(f"## {severity_icons[severity]} {severity.title()} ({len(items)})")
        lines.append("")

        for drift in items:
            lines.append(f"### [{drift.type}] {drift.id}")
            lines.append("")
            lines.append(f"**Description**: {drift.description}")
            if drift.ssot_item:
                lines.append(f"**SSOT**: `{drift.ssot_item}`")
            if drift.code_item:
                lines.append(f"**Code**: `{drift.code_item}`")
            lines.append(f"**Suggestion**: {drift.suggestion}")
            lines.append("")

    return "\n".join(lines)


def get_coverage_summary(project: str) -> str:
    """å–å¾—æ¸¬è©¦è¦†è“‹ç¼ºå£æ‘˜è¦"""
    gaps = detect_coverage_gaps(project)

    lines = [
        "# Test Coverage Gaps",
        "",
        f"**Project**: {project}",
        f"**Gaps found**: {len(gaps)}",
        "",
    ]

    if not gaps:
        lines.append("All important code has test coverage. âœ…")
        return "\n".join(lines)

    lines.append("## Uncovered Code")
    lines.append("")
    lines.append("| Kind | Name | File | Line |")
    lines.append("|------|------|------|------|")

    for gap in gaps[:50]:  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
        lines.append(
            f"| {gap['node_kind']} | `{gap['name']}` | {gap['file_path']} | {gap['line_start']} |"
        )

    if len(gaps) > 50:
        lines.append(f"\n... and {len(gaps) - 50} more")

    return "\n".join(lines)
